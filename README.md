# ğŸ¤ Real-time Vietnamese-English Speech Translation

Há»‡ thá»‘ng dá»‹ch tiáº¿ng nÃ³i Viá»‡t-Anh thá»i gian thá»±c, sá»­ dá»¥ng cho giáº£ng Ä‘Æ°á»ng.

## ğŸš€ Quick Start

```bash
# 1. Clone vÃ  cÃ i Ä‘áº·t
git clone https://github.com/Senju14/Speech_to_text-realtime-for-lecture-hall.git
cd Speech_to_text-realtime-for-lecture-hall

# 2. Setup Modal CLI
pip install modal
modal token new

# 3. Deploy
modal deploy main.py
```

Truy cáº­p URL Ä‘Æ°á»£c in ra sau khi deploy.

## ğŸ“ Kiáº¿n trÃºc há»‡ thá»‘ng

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         FRONTEND (Browser)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ¤ Microphone â”€â”€â–º AudioWorklet â”€â”€â–º Resample 16kHz â”€â”€â–º Base64   â”‚
â”‚                                                          â”‚       â”‚
â”‚  ğŸ“Š UI Manager â—„â”€â”€ WebSocket â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚     â””â”€â”€ Transcript Display (Vi + En)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚ WebSocket
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      BACKEND (Modal GPU)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  Audio â”€â”€â–º VAD (Energy) â”€â”€â–º Buffer â”€â”€â–º Faster-Whisper â”€â”€â–º Text  â”‚
â”‚                                              â”‚                    â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                              â–¼                                    â”‚
â”‚                    Hallucination Filter                           â”‚
â”‚                    (Pattern + WPS + Confidence)                   â”‚
â”‚                              â”‚                                    â”‚
â”‚                              â–¼                                    â”‚
â”‚                    NLLB Translator â”€â”€â–º English Text               â”‚
â”‚                              â”‚                                    â”‚
â”‚                              â–¼                                    â”‚
â”‚                    WebSocket Response                             â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Tech Stack

| Component | Technology | Purpose |
|-----------|------------|---------|
| ASR | Faster-Whisper (large-v3) | Vietnamese speech recognition |
| Translation | NLLB 3.3B | Viâ†’En neural machine translation |
| VAD | Energy-based RMS | Voice activity detection |
| Streaming | WebSocket | Real-time bidirectional |
| Backend | Modal + FastAPI | Serverless GPU compute |
| Frontend | Vanilla JS + CSS | Lightweight UI |

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n

```
â”œâ”€â”€ main.py                 # Modal entry point
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ asr.py             # Faster-Whisper ASR
â”‚   â”œâ”€â”€ translation.py     # NLLB translator
â”‚   â”œâ”€â”€ handler.py         # WebSocket session handler
â”‚   â”œâ”€â”€ config.py          # Configuration
â”‚   â””â”€â”€ vad.py             # Voice Activity Detection
â””â”€â”€ frontend/
    â”œâ”€â”€ index.html         # Main UI
    â”œâ”€â”€ style.css          # Styling
    â””â”€â”€ js/
        â”œâ”€â”€ main.js        # App controller
        â”œâ”€â”€ audio.js       # Audio capture
        â”œâ”€â”€ socket.js      # WebSocket client
        â””â”€â”€ ui.js          # UI manager
```

## âš™ï¸ Cáº¥u hÃ¬nh

Chá»‰nh sá»­a `backend/config.py`:

```python
WHISPER_MODEL = "large-v3"      # Model size
WHISPER_LANGUAGE = "vi"         # Force Vietnamese
MODAL_GPU = "A100"              # GPU type
VAD_THRESHOLD = 0.01            # Voice detection sensitivity
MAX_BUFFER_DURATION = 8.0       # Max audio buffer (seconds)
```

## ğŸ”¬ PhÆ°Æ¡ng phÃ¡p chÃ­nh (cho Paper)

1. **Streaming ASR Pipeline**
   - Chunk-based processing vá»›i VAD
   - Faster-Whisper cho low-latency

2. **Hallucination Detection**
   - Pattern matching (YouTube artifacts)
   - Words-per-second validation
   - Confidence thresholding

3. **Cascade Translation**
   - NLLB 3.3B vá»›i safetensors
   - Async translation pipeline

4. **Real-time WebSocket Protocol**
   - Binary audio streaming
   - JSON transcript responses

## ğŸ“Š Metrics

- **Latency**: ~0.5-1s (partial), ~2-3s (final + translation)
- **GPU**: A100 40GB
- **Model load**: ~25s cold start

## ğŸ“ˆ Evaluation Results

Streaming ASR benchmark on 100 samples per dataset:

| Model | Dataset | GPU | WER | CER | TTFT | RTF |
|-------|---------|-----|-----|-----|------|-----|
| Whisper | vlsp2020 | A100 | 26.94% | 22.19% | 4ms | 0.070x |
| Whisper | earnings22 | A100 | 25.44% | 19.65% | 1ms | 0.060x |
| PhoWhisper | vlsp2020 | A100 | **16.16%** | **14.82%** | 4ms | 0.081x |
| PhoWhisper | earnings22 | A100 | 29.59% | 21.80% | 2ms | 0.088x |

**Key findings:**
- PhoWhisper achieves **16.16% WER** on Vietnamese (VLSP2020) - 40% better than Whisper
- Whisper performs better on English (earnings22)
- RTF ~0.06-0.09x = **~11-17x faster than real-time**

See `test/README.md` for running evaluations.

## ğŸ“ License

MIT License

